{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyrpV4K0k6XGw7C0Dec95v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binaryninja437/Gemini-API-Integration-Using-Python/blob/main/PromptAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemini API Integration with Python"
      ],
      "metadata": {
        "id": "UaC_I1Cim0uH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from IPython.display import HTML, Markdown, display"
      ],
      "metadata": {
        "id": "BgO7OQHyfIVB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.api_core import retry\n",
        "\n",
        "\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "genai.models.Models.generate_content = retry.Retry(\n",
        "    predicate=is_retriable)(genai.models.Models.generate_content)"
      ],
      "metadata": {
        "id": "5QPVRII_fU_O"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "JnHdncZ4fcCF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=\"Explain AI to me like I'm a kid.\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAvbk4pffvNV",
        "outputId": "ebb01546-7de8-4bed-a10d-e3a934c22972"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, imagine you have a really, really smart puppy. This puppy can learn new tricks, but instead of treats, we teach it with lots and lots of examples. That puppy is a bit like AI!\n",
            "\n",
            "**Think of it like this:**\n",
            "\n",
            "*   **You want the puppy to recognize cats.** You show it tons of pictures of cats: fluffy cats, skinny cats, black cats, white cats, even cartoon cats.\n",
            "*   **The puppy looks at all these pictures and starts to notice things:** pointy ears, whiskers, maybe the way they move.\n",
            "*   **The puppy builds a \"brain\"** (we call it a model) that helps it tell the difference between a cat and a dog.\n",
            "*   **Then you show the puppy a new picture.** If the puppy thinks it's a cat, it might bark once. If it thinks it's a dog, it might bark twice.\n",
            "*   **If it's right, you say \"Good job!\"** If it's wrong, you correct it and show it more cat pictures.\n",
            "*   **After lots and lots of training,** the puppy becomes really good at recognizing cats, even if it's never seen that specific cat before!\n",
            "\n",
            "That's basically AI!  We give computers lots of data, like pictures or words, and they learn patterns. They can then use these patterns to make predictions, answer questions, write stories, or even play games.\n",
            "\n",
            "**It's like having a super smart student who learns from examples, but instead of a notebook, it uses a computer!**\n",
            "\n",
            "So, AI isn't really alive like a puppy, but it can do amazing things by learning from information. And just like a puppy needs training, AI needs lots and lots of data to learn and get better at what it does!\n",
            "\n",
            "**Different kinds of \"puppy\" AI do different things:**\n",
            "\n",
            "*   **Some \"puppies\" can write stories** based on what they've read.\n",
            "*   **Some \"puppies\" can help doctors find diseases** in X-rays.\n",
            "*   **Some \"puppies\" can drive cars!**\n",
            "\n",
            "AI is still learning, but it's getting smarter every day!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FcT3pHwXf4OI",
        "outputId": "5966ace9-ff02-4f19-a154-dde52b6b4291"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, imagine you have a really, really smart puppy. This puppy can learn new tricks, but instead of treats, we teach it with lots and lots of examples. That puppy is a bit like AI!\n\n**Think of it like this:**\n\n*   **You want the puppy to recognize cats.** You show it tons of pictures of cats: fluffy cats, skinny cats, black cats, white cats, even cartoon cats.\n*   **The puppy looks at all these pictures and starts to notice things:** pointy ears, whiskers, maybe the way they move.\n*   **The puppy builds a \"brain\"** (we call it a model) that helps it tell the difference between a cat and a dog.\n*   **Then you show the puppy a new picture.** If the puppy thinks it's a cat, it might bark once. If it thinks it's a dog, it might bark twice.\n*   **If it's right, you say \"Good job!\"** If it's wrong, you correct it and show it more cat pictures.\n*   **After lots and lots of training,** the puppy becomes really good at recognizing cats, even if it's never seen that specific cat before!\n\nThat's basically AI!  We give computers lots of data, like pictures or words, and they learn patterns. They can then use these patterns to make predictions, answer questions, write stories, or even play games.\n\n**It's like having a super smart student who learns from examples, but instead of a notebook, it uses a computer!**\n\nSo, AI isn't really alive like a puppy, but it can do amazing things by learning from information. And just like a puppy needs training, AI needs lots and lots of data to learn and get better at what it does!\n\n**Different kinds of \"puppy\" AI do different things:**\n\n*   **Some \"puppies\" can write stories** based on what they've read.\n*   **Some \"puppies\" can help doctors find diseases** in X-rays.\n*   **Some \"puppies\" can drive cars!**\n\nAI is still learning, but it's getting smarter every day!\n"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model='gemini-2.0-flash', history=[])\n",
        "response = chat.send_message('Hello! My name is Udit.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jlTcgeygA-2",
        "outputId": "3b860070-3815-4dcd-8a2d-6958a15238b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Udit! It's nice to meet you. How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message('Can you tell me something interesting about horse?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4MMvDMdgFMy",
        "outputId": "ad784911-ef53-403a-d034-de98be1182ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's an interesting fact about horses:\n",
            "\n",
            "**Horses can sleep standing up because they have a \"stay apparatus\" in their legs.**\n",
            "\n",
            "This unique arrangement of tendons and ligaments allows them to lock their leg joints, so they don't have to use their muscles to stay upright while resting. This is a crucial adaptation for survival, as it allows them to quickly flee from predators even when they are sleeping!\n",
            "\n",
            "Would you like to know another interesting fact about horses?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "YSMlLnabgRyV",
        "outputId": "477819e7-84cf-4027-d40f-92258569d1df"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here's an interesting fact about horses:\n\n**Horses can sleep standing up because they have a \"stay apparatus\" in their legs.**\n\nThis unique arrangement of tendons and ligaments allows them to lock their leg joints, so they don't have to use their muscles to stay upright while resting. This is a crucial adaptation for survival, as it allows them to quickly flee from predators even when they are sleeping!\n\nWould you like to know another interesting fact about horses?\n"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message('Do you remember what my name is?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LEBSP4jgdb3",
        "outputId": "78ffe2ef-eba2-4bca-82ee-ee53f1cbea42"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, your name is Udit.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting Model"
      ],
      "metadata": {
        "id": "kfjx7YZdgg-3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "  print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB_O8VTggnZw",
        "outputId": "85f4350d-9057-4c16-c326-8c531de064f6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-preview\n",
            "models/veo-3.0-fast-generate-preview\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/veo-3.1-generate-preview\n",
            "models/veo-3.1-fast-generate-preview\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "for model in client.models.list():\n",
        "  if model.name == 'models/gemini-2.0-flash':\n",
        "    pprint(model.to_json_dict())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BRVXnzJgom1",
        "outputId": "6cb26c8a-6b93-4622-d457-49cbbe569815"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'description': 'Gemini 2.0 Flash',\n",
            " 'display_name': 'Gemini 2.0 Flash',\n",
            " 'input_token_limit': 1048576,\n",
            " 'name': 'models/gemini-2.0-flash',\n",
            " 'output_token_limit': 8192,\n",
            " 'supported_actions': ['generateContent',\n",
            "                       'countTokens',\n",
            "                       'createCachedContent',\n",
            "                       'batchGenerateContent'],\n",
            " 'tuned_model_info': {},\n",
            " 'version': '2.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "short_config = types.GenerateContentConfig(max_output_tokens=200)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash',\n",
        "    config=short_config,\n",
        "    contents='Write a 1000 word essay on the importance of spices in modern society.')\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtQUBAaWgr1p",
        "outputId": "0db86f6e-7520-46ab-e8e0-fbaf48c71754"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## The Spice of Life: An Indispensable Ingredient in Modern Society\n",
            "\n",
            "Spices, those pungent and aromatic treasures derived from various parts of plants, are far more than just culinary embellishments. They are deeply woven into the fabric of modern society, influencing our food, health, culture, economy, and even our understanding of history. From the ubiquitous black pepper to the exotic saffron, spices play an indispensable role, adding depth, complexity, and vitality to our lives in ways that often go unnoticed.\n",
            "\n",
            "One of the most obvious and significant contributions of spices is their transformative power in the culinary world. They are the architects of flavor, capable of elevating the simplest dishes into gastronomic masterpieces. Consider the blandness of a plain chicken breast, utterly transformed by the application of paprika, garlic powder, and chili flakes. Spices unlock the hidden potential of ingredients, creating complex and satisfying flavor profiles that cater to a vast range of palates. They allow us to explore diverse culinary traditions, transporting us to distant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "mRRmmeKMhAP6",
        "outputId": "22eab87a-f61f-45de-bc57-58d67daf38f7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## The Spice of Life: An Indispensable Ingredient in Modern Society\n\nSpices, those pungent and aromatic treasures derived from various parts of plants, are far more than just culinary embellishments. They are deeply woven into the fabric of modern society, influencing our food, health, culture, economy, and even our understanding of history. From the ubiquitous black pepper to the exotic saffron, spices play an indispensable role, adding depth, complexity, and vitality to our lives in ways that often go unnoticed.\n\nOne of the most obvious and significant contributions of spices is their transformative power in the culinary world. They are the architects of flavor, capable of elevating the simplest dishes into gastronomic masterpieces. Consider the blandness of a plain chicken breast, utterly transformed by the application of paprika, garlic powder, and chili flakes. Spices unlock the hidden potential of ingredients, creating complex and satisfying flavor profiles that cater to a vast range of palates. They allow us to explore diverse culinary traditions, transporting us to distant"
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash',\n",
        "    config=short_config,\n",
        "    contents='Write a short poem on moon.')\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKm7Z_xkjZy0",
        "outputId": "1c2a3256-c321-4277-8348-ac943f1930b6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A silver disc in velvet skies,\n",
            "A watchful eye that never lies.\n",
            "It bathes the world in gentle light,\n",
            "And guides the dreams throughout the night.\n",
            "\n",
            "A silent beacon, pale and grand,\n",
            "A mystery held in its hand.\n",
            "The moon, a pearl, a shining grace,\n",
            "Forever circling time and space.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "KtP3XO-hjijd",
        "outputId": "6d9b52e3-5ad8-48bd-a1a1-183c9d447000"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A silver disc in velvet skies,\nA watchful eye that never lies.\nIt bathes the world in gentle light,\nAnd guides the dreams throughout the night.\n\nA silent beacon, pale and grand,\nA mystery held in its hand.\nThe moon, a pearl, a shining grace,\nForever circling time and space.\n"
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Using Gemini"
      ],
      "metadata": {
        "id": "_oJCgl9Gp-xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code_prompt = \"\"\"\n",
        "Write a java function to calculate the factorial of a number. No explanation, provide only the code.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash',\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=1,\n",
        "        max_output_tokens=1024,\n",
        "    ),\n",
        "    contents=code_prompt)\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "kdydg0GwkCyJ",
        "outputId": "9e1e2a10-cc1d-4493-afca-fc4579b088f6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```java\nclass Solution {\n    /**\n     * Calculates the factorial of a number.\n     *\n     * @param n The input number.\n     * @return The factorial of n.\n     */\n    public long factorial(int n) {\n        if (n == 0) {\n            return 1;\n        } else {\n            return n * factorial(n - 1);\n        }\n    }\n}\n```"
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inWHluxamRjg"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}