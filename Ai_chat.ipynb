{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPegePKGcvy1SC9VW0boZ+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binaryninja437/Gemini-API-Integration-Using-Python/blob/main/Ai_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2277Vlan_lGI"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from IPython.display import HTML, Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.api_core import retry\n",
        "\n",
        "\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "genai.models.Models.generate_content = retry.Retry(\n",
        "    predicate=is_retriable)(genai.models.Models.generate_content)\n",
        ""
      ],
      "metadata": {
        "id": "Z6-ypzjMAe-b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "eDVQ9DrxA3_q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=\"Explain AI to me like I'm a kid.\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm4QWjYnA7v1",
        "outputId": "04e38ff3-421f-4e5a-9f53-3d864ec64cfa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, imagine you have a really smart robot toy. This robot isn't just programmed to do a few things like walk and talk. Instead, it can *learn* things like you do!\n",
            "\n",
            "That's kind of what AI is: **making computers or robots act like they're smart and can learn.**\n",
            "\n",
            "Think of it like this:\n",
            "\n",
            "*   **Normal toys:** You press a button, and they do a specific thing. Like a car that only goes forward.\n",
            "*   **AI toys:** You can teach them things! You can show them pictures of cats and dogs, and eventually, they learn to tell the difference. Then, when you show them a new picture, they can say, \"That's a cat!\" or \"That's a dog!\"\n",
            "\n",
            "**How does it learn?**\n",
            "\n",
            "We feed the computer lots and lots of information, like all the pictures of cats and dogs. The computer looks for patterns and rules in that information. It uses those rules to make guesses. If it guesses wrong, we tell it, and it learns from its mistake.\n",
            "\n",
            "**Where do you see AI?**\n",
            "\n",
            "*   **Your phone:** When your phone recognizes your face, that's AI!\n",
            "*   **Games:** When you play a game against the computer, and it gets harder as you get better, that's AI learning from you!\n",
            "*   **Asking questions on the internet:** When you ask a question on the internet, AI helps find the best answers for you!\n",
            "\n",
            "**Is AI perfect?**\n",
            "\n",
            "Nope! Just like you make mistakes when you're learning, AI can make mistakes too. Sometimes it might get things wrong, but it's always learning and getting better!\n",
            "\n",
            "So, AI is all about making computers and robots smart enough to learn, solve problems, and do things that usually only people can do. It's like a super-smart toy that's still learning and growing!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "veYeqanFBALj",
        "outputId": "d9d9445d-6fd1-4e0c-9021-a33ab5ca8128"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, imagine you have a really smart robot toy. This robot isn't just programmed to do a few things like walk and talk. Instead, it can *learn* things like you do!\n\nThat's kind of what AI is: **making computers or robots act like they're smart and can learn.**\n\nThink of it like this:\n\n*   **Normal toys:** You press a button, and they do a specific thing. Like a car that only goes forward.\n*   **AI toys:** You can teach them things! You can show them pictures of cats and dogs, and eventually, they learn to tell the difference. Then, when you show them a new picture, they can say, \"That's a cat!\" or \"That's a dog!\"\n\n**How does it learn?**\n\nWe feed the computer lots and lots of information, like all the pictures of cats and dogs. The computer looks for patterns and rules in that information. It uses those rules to make guesses. If it guesses wrong, we tell it, and it learns from its mistake.\n\n**Where do you see AI?**\n\n*   **Your phone:** When your phone recognizes your face, that's AI!\n*   **Games:** When you play a game against the computer, and it gets harder as you get better, that's AI learning from you!\n*   **Asking questions on the internet:** When you ask a question on the internet, AI helps find the best answers for you!\n\n**Is AI perfect?**\n\nNope! Just like you make mistakes when you're learning, AI can make mistakes too. Sometimes it might get things wrong, but it's always learning and getting better!\n\nSo, AI is all about making computers and robots smart enough to learn, solve problems, and do things that usually only people can do. It's like a super-smart toy that's still learning and growing!\n"
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model='gemini-2.0-flash', history=[])\n",
        "response = chat.send_message('Hello! My name is Udit.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deN4MUs0BFJq",
        "outputId": "381a0a7c-516a-41c8-9125-5198192e34d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Udit! It's nice to meet you. How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message('Can you tell me something interesting about cat in 100 words?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePydQ0FdBfIO",
        "outputId": "016a3901-a9f2-430e-9bdd-3c9f2867201a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cats, domesticated for thousands of years, are fascinating creatures. Their purr, a unique vocalization, vibrates at a frequency that can promote healing in both themselves and humans. They are incredibly agile hunters, possessing exceptional night vision and flexible bodies that allow them to squeeze into tight spaces. Each cat's nose print is unique, like a human fingerprint. While they are known for their independence, they also form strong bonds with their humans and other animals. Their mysterious nature and captivating behaviors make them beloved companions worldwide.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "3Eav_8v9Bm12",
        "outputId": "2bec78f4-b4c5-4af1-c63a-85d6d17f76ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Cats, domesticated for thousands of years, are fascinating creatures. Their purr, a unique vocalization, vibrates at a frequency that can promote healing in both themselves and humans. They are incredibly agile hunters, possessing exceptional night vision and flexible bodies that allow them to squeeze into tight spaces. Each cat's nose print is unique, like a human fingerprint. While they are known for their independence, they also form strong bonds with their humans and other animals. Their mysterious nature and captivating behaviors make them beloved companions worldwide.\n"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message('Do you remember what my name is?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_H0nD8DBurO",
        "outputId": "2eeed5f4-77a6-4b35-e9e0-a3ee6fb3c66d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, your name is Udit.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message('No my name is john')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaHgzTofDFGF",
        "outputId": "5b0f04b0-c462-4793-c6d9-59b537ac19c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My apologies, John. I was mistaken and retained the previous name provided. It seems I got confused. Thanks for correcting me! How can I help you, John?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting Model"
      ],
      "metadata": {
        "id": "NWeA7Dp-DZcD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "  print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv3JgSwrDz6r",
        "outputId": "7a8c2e38-3968-4ff2-cb84-3140fb1486eb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/veo-3.1-generate-preview\n",
            "models/veo-3.1-fast-generate-preview\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "for model in client.models.list():\n",
        "  if model.name == 'models/gemini-2.0-flash':\n",
        "    pprint(model.to_json_dict())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eop0aRvAD29U",
        "outputId": "86647b53-fb12-4b44-b6c4-26d7ea172a28"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'description': 'Gemini 2.0 Flash',\n",
            " 'display_name': 'Gemini 2.0 Flash',\n",
            " 'input_token_limit': 1048576,\n",
            " 'name': 'models/gemini-2.0-flash',\n",
            " 'output_token_limit': 8192,\n",
            " 'supported_actions': ['generateContent',\n",
            "                       'countTokens',\n",
            "                       'createCachedContent',\n",
            "                       'batchGenerateContent'],\n",
            " 'tuned_model_info': {},\n",
            " 'version': '2.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "short_config = types.GenerateContentConfig(max_output_tokens=200)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash',\n",
        "    config=short_config,\n",
        "    contents='Write a 1000 word essay on the importance of spices in modern society.')\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5dKLDSxI1F8",
        "outputId": "61112f4b-ad37-4e31-90ad-6feac0fee06f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## The Unseen Architects of Flavor: The Enduring Importance of Spices in Modern Society\n",
            "\n",
            "Spices, those aromatic seeds, barks, roots, and fruits, are often relegated to the back of kitchen cabinets, silent sentinels of flavor. Yet, their presence is ubiquitous, influencing everything from our culinary experiences to our health and even our global economies. In modern society, spices are far more than just flavor enhancers; they are cultural touchstones, engines of trade, and potential keys to unlocking better health. Understanding their enduring importance requires recognizing their multifaceted roles in shaping our world.\n",
            "\n",
            "Firstly, spices remain the cornerstones of diverse and vibrant cuisines. In an increasingly homogenized global landscape, where fast food chains and convenience meals threaten to erase culinary distinctions, spices act as bulwarks of cultural identity. Think of the fiery heat of chili peppers in Mexican cuisine, the earthy warmth of cumin in Moroccan tagines, or the delicate floral notes of saffron in Spanish paella. Each spice, carefully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "PQ2mancuI6lV",
        "outputId": "8dc171a5-192f-4a72-cbbd-ef16d6006698"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## The Unseen Architects of Flavor: The Enduring Importance of Spices in Modern Society\n\nSpices, those aromatic seeds, barks, roots, and fruits, are often relegated to the back of kitchen cabinets, silent sentinels of flavor. Yet, their presence is ubiquitous, influencing everything from our culinary experiences to our health and even our global economies. In modern society, spices are far more than just flavor enhancers; they are cultural touchstones, engines of trade, and potential keys to unlocking better health. Understanding their enduring importance requires recognizing their multifaceted roles in shaping our world.\n\nFirstly, spices remain the cornerstones of diverse and vibrant cuisines. In an increasingly homogenized global landscape, where fast food chains and convenience meals threaten to erase culinary distinctions, spices act as bulwarks of cultural identity. Think of the fiery heat of chili peppers in Mexican cuisine, the earthy warmth of cumin in Moroccan tagines, or the delicate floral notes of saffron in Spanish paella. Each spice, carefully"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash',\n",
        "    config=short_config,\n",
        "    contents='Write a short poem on moon.')\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55O4ReH9JAtb",
        "outputId": "73233359-1a60-4135-a3b7-c89bae7648b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A silver coin in velvet skies,\n",
            "A watchful eye, that never lies.\n",
            "It bathes the world in gentle gleam,\n",
            "A silent whisper, in a dream.\n",
            "\n",
            "The tide it pulls, with mystic grace,\n",
            "A pale reflection on its face.\n",
            "A lonely sentinel above,\n",
            "A beacon whispering of love.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5eyOFHTdJFol",
        "outputId": "20859cd0-518c-4270-c44d-95a1d689039b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A silver coin in velvet skies,\nA watchful eye, that never lies.\nIt bathes the world in gentle gleam,\nA silent whisper, in a dream.\n\nThe tide it pulls, with mystic grace,\nA pale reflection on its face.\nA lonely sentinel above,\nA beacon whispering of love.\n"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding Using ChatGemini"
      ],
      "metadata": {
        "id": "kUd2MdNRJLAv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "code_prompt = \"\"\"\n",
        "Write a java function to calculate the factorial of a number. No explanation, provide only the code.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash',\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=1,\n",
        "        max_output_tokens=1024,\n",
        "    ),\n",
        "    contents=code_prompt)\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "a0gMTGgzJSPs",
        "outputId": "5872361b-9848-4b0f-9550-cf873f803df7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```java\nclass Solution {\n    /**\n     * Calculates the factorial of a non-negative integer.\n     *\n     * @param n The non-negative integer.\n     * @return The factorial of n.  Returns 1 if n is 0.\n     * @throws IllegalArgumentException if n is negative.\n     */\n    public long factorial(int n) {\n        if (n < 0) {\n            throw new IllegalArgumentException(\"Factorial is not defined for negative numbers.\");\n        }\n        if (n == 0) {\n            return 1;\n        }\n        long result = 1;\n        for (int i = 1; i <= n; i++) {\n            result *= i;\n        }\n        return result;\n    }\n}\n```"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message('Also explain me the code')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWaTMpaIJa-Y",
        "outputId": "3a6b8982-164f-4e13-8f53-ddd5716d71d5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, John, please provide the code you'd like me to explain. I need the actual code to be able to break it down and tell you what it does.  I can help with many languages, including Python, JavaScript, Java, C++, and more. Just paste it in!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}